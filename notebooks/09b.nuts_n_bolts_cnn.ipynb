{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "- Create a Convolutional Neural Network for classifying nuts and bots\n",
    "- To learn the use of commonly used deep learning layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,\\\n",
    "Conv2D, MaxPooling2D\n",
    "import skimage\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '../data/nuts_n_bolts_master/all_dl/train'\n",
    "test_path = '../data/nuts_n_bolts_master/all_dl/test'\n",
    "val_path = '../data/nuts_n_bolts_master/all_dl/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 50x65\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 50x65\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a simple CNN model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct a model in keras for nuts_and_bolts classfication\n",
    "# The model consists of two convolutional layers\n",
    "# Declare a sequential model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare 2 layers each containing 32 kernel of 3 *3 convolutional filters for the model with input shape = (50,65,3) and activation layer in each layer is relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare rest of the network for the model\n",
    "- Add a maxpooling layer with pool_size - (2,2)\n",
    "- Then flatten the model\n",
    "- Add two fully connected layer, the first one had 128 neurons with relu activation and the second one has w neurons with softmax activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the mode with cross_entropy loss and adam optimiser and with the metrics to be accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 76s - loss: 0.4637 - acc: 0.8183 - val_loss: 0.1403 - val_acc: 0.9400\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 79s - loss: 0.1195 - acc: 0.9557 - val_loss: 0.1617 - val_acc: 0.9100\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 95s - loss: 0.0801 - acc: 0.9703 - val_loss: 0.2214 - val_acc: 0.8900\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 68s - loss: 0.1033 - acc: 0.9677 - val_loss: 0.1410 - val_acc: 0.9600\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 101s - loss: 0.0534 - acc: 0.9888 - val_loss: 0.1599 - val_acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121b01c50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's increase the number of convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets test results for our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets analyse the effect of adding a few drop out layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model to analyse if dropout increases accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Let's try out different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activations = ['relu','tanh','sigmoid']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function to construct and evaluate a model to make the comparison of different loss functions easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_and_evaluate_model(actv):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation= actv))\n",
    "    model.add(Dense(2, activation= actv))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=2,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)\n",
    "    score = model.evaluate_generator(test_generator, steps=50)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for actv in activations:\n",
    "    print('ACTIVATION',i,'\\n')\n",
    "    %timeit -n1 -r1 build_and_evaluate_model(actv)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bolt_path = '../data/nuts_n_bolts_master/all_dl/test/bolts/'\n",
    "nut_path = '../data/nuts_n_bolts_master/all_dl/test/nuts'\n",
    "image_paths = [os.path.join(bolt_path, img_name) for img_name in os.listdir(bolt_path)]\n",
    "image_paths += [os.path.join(nut_path, img_name) for img_name in os.listdir(nut_path)]\n",
    "test_images = np.zeros((len(image_paths),50,65,3))\n",
    "\n",
    "for ind,image_name in enumerate(image_paths):\n",
    "    test_images[ind, :, :, :] = resize(imread(image_name), (50,65,3))\n",
    "    \n",
    "prediction = model.predict(test_images)\n",
    "labels = ['nuts' if img_pred[0] > img_pred[1] else 'bolts' for img_pred in prediction]\n",
    "image_names = [os.path.basename(path) for path in image_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Display all nuts image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pred in labels:\n",
    "  if pred == 'nuts':\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images[ind,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display all bolt images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  if pred == 'bolts':\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images[ind,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
