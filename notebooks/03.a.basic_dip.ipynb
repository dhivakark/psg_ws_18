{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display an image in opencv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "tyrion_image = cv2.imread('../data/tyrion.jpg', 0)\n",
    "\n",
    "# Draw the image and show the matrix\n",
    "print(tyrion_image[:10, :10])\n",
    "plt.imshow(tyrion_image, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cersei_image = cv2.imread('../data/cersei.jpg')\n",
    "\n",
    "# Draw the image and show the matrix\n",
    "print('Red ->\\n', cersei_image[:10, :10, 0], )\n",
    "plt.imshow(cv2.cvtColor(cersei_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average color of the image\n",
    "# find average per row\n",
    "# np.average() takes in an axis argument which finds the average across that axis. \n",
    "average_color_per_row = np.average(cersei_image, axis=0)\n",
    "\n",
    "# find average across average per row\n",
    "average_color = np.average(average_color_per_row, axis=0)\n",
    "\n",
    "# convert back to uint8\n",
    "average_color = np.uint8(average_color)\n",
    "print(average_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('../data/image_processing/color_pallate.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "blue_lower = np.array([110, 0, 0])\n",
    "blue_upper = np.array([140, 255, 255])\n",
    "mask = cv2.inRange(image, blue_lower, blue_upper)\n",
    "res = cv2.bitwise_and(image,image, mask= mask)\n",
    "res = cv2.cvtColor(res, cv2.COLOR_HSV2RGB)\n",
    "plt.imshow(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image thresholding\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = tyrion_image\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "#for img in images:\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_image = cv2.imread('../data/image_processing/histogram.jpg')\n",
    "hist,bins = np.histogram(hist_image.ravel(),256,[0,256])\n",
    "print(hist)\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram using matplotlib for a grey scale image\n",
    "plt.hist(hist_image.ravel(),256,[0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram using matplotlob for color image\n",
    "hist_image = cv2.imread('../data/image_processing/histogram2.jpeg')\n",
    "plt.imshow(cv2.cvtColor(hist_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([hist_image],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalisation\n",
    "lw_cntrst_img = cv2.imread('../data/image_processing/low_contrast3.jpg',0)\n",
    "plt.hist(lw_cntrst_img.ravel(),256,[0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equ = cv2.equalizeHist(lw_cntrst_img)\n",
    "res = np.hstack((lw_cntrst_img,equ))\n",
    "plt.imshow(res, 'gray')\n",
    "plt.show()\n",
    "plt.hist(equ.ravel(),256,[0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im = cv2.imread('../data/image_processing/shapes.jpg')\n",
    "imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray, 220, 255, 0)\n",
    "plt.imshow(thresh,'gray')\n",
    "plt.show()\n",
    "im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(im, contours, -1, (0,255,0), 3)\n",
    "plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "img = cv2.imread('../data/opencv_numpy/lena_noisy.png')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = cv2.blur(img, (5,5),0)\n",
    "gaussian_blur = cv2.GaussianBlur(img, (5,5), 0)\n",
    "median_blur = cv2.medianBlur(img, 5 ,0)\n",
    "bilateral = cv2.bilateralFilter(img,9,75,75)\n",
    "\n",
    "titles = ['Original Image','average','gaussian_blur','median_blur','bilateral']\n",
    "images = [img, average, gaussian_blur, median_blur, bilateral]\n",
    "\n",
    "#for img in images:\n",
    "for i in range(5):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect edges in an image using opencv on the input noisy image\n",
    "edges = cv2.Canny(img,100,200)\n",
    "plt.imshow(edges, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect edges in an image using opencv on the smoothened image\n",
    "edges = cv2.Canny(average,100,200)\n",
    "\n",
    "plt.imshow(edges, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian edge detector and sobel gradients\n",
    "img = cv2.imread('../data/image_processing/gradients.png',0)\n",
    "\n",
    "# Output dtype = cv2.CV_8U\n",
    "sobelx8u = cv2.Sobel(img,cv2.CV_8U,1,0,ksize=5)\n",
    "\n",
    "# Output dtype = cv2.CV_64F. Then take its absolute and convert to cv2.CV_8U\n",
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1,4,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,4,2),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobelx'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,4,3),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobely'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,4,4),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('laplacian'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do morphological operations\n",
    "# First lets start with erosion\n",
    "img1 = cv2.imread('../data/image_processing/j_image.png',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img1,kernel,iterations = 1)\n",
    "\n",
    "plt.subplot(1,2,1),plt.imshow(img1,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,2,2),plt.imshow(erosion,cmap = 'gray')\n",
    "plt.title('eroded_image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(img1,kernel,iterations = 1)\n",
    "\n",
    "plt.subplot(1,2,1),plt.imshow(img1,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,2,2),plt.imshow(dilation,cmap = 'gray')\n",
    "plt.title('dilated_image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('../data/image_processing/noisy_img.png',0)\n",
    "opening1 = cv2.morphologyEx(img1, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "img2 = cv2.imread('../data/image_processing/circles.png',0)\n",
    "opening2 = cv2.morphologyEx(img2, cv2.MORPH_OPEN, kernel,iterations = 6)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(img1,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,2),plt.imshow(opening1,cmap = 'gray')\n",
    "plt.title('opening'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(img2,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(opening2,cmap = 'gray')\n",
    "plt.title('opening'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets try morphological closing\n",
    "\n",
    "img1 = cv2.imread('../data/image_processing/j_with_holes.png',0)\n",
    "closing_img1 = cv2.morphologyEx(img1, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "img2 = cv2.imread('../data/image_processing/circle_with_holes.png',0)\n",
    "closing_img2_iter1 = cv2.morphologyEx(img2, cv2.MORPH_CLOSE, kernel, iterations = 1)\n",
    "closing_img2_iter3 = cv2.morphologyEx(img2, cv2.MORPH_CLOSE, kernel, iterations = 3)\n",
    "closing_img2_iter4 = cv2.morphologyEx(img2, cv2.MORPH_CLOSE, kernel, iterations = 4)\n",
    "closing_img2_iter5 = cv2.morphologyEx(img2, cv2.MORPH_CLOSE, kernel, iterations = 5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2,5,1),plt.imshow(img1,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,5,2),plt.imshow(closing_img1,cmap = 'gray')\n",
    "plt.title('closing'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,5,6),plt.imshow(img2,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,5,7),plt.imshow(closing_img2_iter1,cmap = 'gray')\n",
    "plt.title('closing_1'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,5,8),plt.imshow(closing_img2_iter3,cmap = 'gray')\n",
    "plt.title('closing_3'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,5,9),plt.imshow(closing_img2_iter4,cmap = 'gray')\n",
    "plt.title('closing_4'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,5,10),plt.imshow(closing_img2_iter5,cmap = 'gray')\n",
    "plt.title('closing_5'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
